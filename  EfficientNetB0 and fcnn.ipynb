{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478fa6da-389e-439a-961e-03b62b61326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "weight_path = '/kaggle/input/efficientnetb0/efficientnetb0_notop.h5'\n",
    "# Load EfficientNetB0 model without the top layer\n",
    "base_model = EfficientNetB0(weights=weight_path, include_top=False, pooling='avg')\n",
    "\n",
    "# CutMix Augmentation\n",
    "def cutmix(image, image2, alpha=1.0):\n",
    "    h, w, _ = image.shape\n",
    "    h2, w2, _ = image2.shape\n",
    "\n",
    "    if (h2 != h) or (w2 != w):\n",
    "        image2 = cv2.resize(image2, (w, h))\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    cut_rat = np.sqrt(1.0 - lam)\n",
    "    cut_w = int(w * cut_rat)\n",
    "    cut_h = int(h * cut_rat)\n",
    "\n",
    "    cx = np.random.randint(w)\n",
    "    cy = np.random.randint(h)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, w)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, h)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, w)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, h)\n",
    "\n",
    "    if bbx1 >= bbx2 or bby1 >= bby2:\n",
    "        return image, lam\n",
    "\n",
    "    new_image = image.copy()\n",
    "    new_image[bby1:bby2, bbx1:bbx2, :] = image2[bby1:bby2, bbx1:bbx2, :]\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (h * w))\n",
    "\n",
    "    return new_image, lam\n",
    "\n",
    "# Extract features using EfficientNetB0\n",
    "def extract_features(img_path, model, img_size=(224, 224)):\n",
    "    img = image.load_img(img_path, target_size=img_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    features = model.predict(img_array)\n",
    "    return features.flatten()\n",
    "\n",
    "# Load and extract features with optional CutMix\n",
    "def load_and_extract_features(csv_path, images_folder, model, apply_cutmix=False):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        image_name = row['id_code']\n",
    "        label = row['diagnosis']\n",
    "        image_path = f\"{images_folder}/{image_name}.png\"\n",
    "\n",
    "        if apply_cutmix:\n",
    "            img = cv2.imread(image_path)\n",
    "            rand_index = np.random.choice(data.index)\n",
    "            random_image_name = data.loc[rand_index, 'id_code']\n",
    "            random_image_path = f\"{images_folder}/{random_image_name}.png\"\n",
    "            img2 = cv2.imread(random_image_path)\n",
    "\n",
    "            cutmix_img, lam = cutmix(img, img2)\n",
    "            cutmix_img = cv2.resize(cutmix_img, (224, 224))\n",
    "            img_array = np.expand_dims(cutmix_img, axis=0)\n",
    "            img_array = preprocess_input(img_array)\n",
    "            feature = model.predict(img_array).flatten()\n",
    "        else:\n",
    "            feature = extract_features(image_path, model)\n",
    "\n",
    "        features.append(feature)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Build fully connected neural network for classification\n",
    "def build_classifier(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(input_shape,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))  # Assuming 5 classes\n",
    "    return model\n",
    "\n",
    "# Compile and train the model\n",
    "def compile_and_train_model(model, X_train, y_train, X_val, y_val, epochs=10, batch_size=32):\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "    return history\n",
    "\n",
    "# Load test data and extract features using EfficientNetB0\n",
    "def load_test_data_and_extract_features(csv_path, images_folder, model):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    features = []\n",
    "    image_names = []\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        image_name = row['id_code']\n",
    "        image_path = f\"{images_folder}/{image_name}.png\"\n",
    "        feature = extract_features(image_path, model)\n",
    "        features.append(feature)\n",
    "        image_names.append(image_name)\n",
    "    \n",
    "    return np.array(features), image_names\n",
    "\n",
    "# Predict test labels and save to CSV\n",
    "def predict_and_generate_csv(model, test_features, image_names, output_csv_path):\n",
    "    predictions = np.argmax(model.predict(test_features), axis=1)\n",
    "    output_df = pd.DataFrame({\n",
    "        'id_code': image_names,\n",
    "        'diagnosis': predictions\n",
    "    })\n",
    "    output_df.to_csv('submission.csv', index=False)\n",
    "    print(f\"Predictions saved to {output_csv_path}\")\n",
    "\n",
    "# Main Program\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths\n",
    "    train_csv_path = '/kaggle/input/aptos2019-blindness-detection/train.csv'\n",
    "    train_images_folder = '/kaggle/input/aptos2019-blindness-detection/train_images'\n",
    "    test_csv_path = '/kaggle/input/aptos2019-blindness-detection/test.csv'\n",
    "    test_images_folder = '/kaggle/input/aptos2019-blindness-detection/test_images'\n",
    "    output_csv_path = '/kaggle/input/aptos2019-blindness-detection/submission.csv'\n",
    "\n",
    "    # 1. Load and extract features from the training data with CutMix augmentation\n",
    "    print(\"Loading and extracting features from training data with CutMix...\")\n",
    "    X, y = load_and_extract_features(train_csv_path, train_images_folder, base_model, apply_cutmix=True)\n",
    "\n",
    "    # 2. Encode labels to numeric values\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # 3. Perform 5-Fold Cross-Validation\n",
    "    n_folds = 5\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y_encoded)):\n",
    "        print(f\"Training fold {fold + 1}/{n_folds}...\")\n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "        \n",
    "        # Build and train FCNN classifier\n",
    "        classifier_model = build_classifier(input_shape=X_train.shape[1])\n",
    "        compile_and_train_model(classifier_model, X_train, y_train, X_val, y_val, epochs=10)\n",
    "        \n",
    "        # Validate the model on this fold\n",
    "        y_val_pred = np.argmax(classifier_model.predict(X_val), axis=1)\n",
    "        accuracy = accuracy_score(y_val, y_val_pred)\n",
    "        fold_accuracies.append(accuracy)\n",
    "        \n",
    "        print(f\"Fold {fold + 1} Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Print overall average accuracy across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    print(f\"Average Cross-Validation Accuracy: {avg_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # 4. Load and extract features from the test data\n",
    "    print(\"Loading and extracting features from test data...\")\n",
    "    test_features, image_names = load_test_data_and_extract_features(test_csv_path, test_images_folder, base_model)\n",
    "\n",
    "    # 5. Predict test labels and generate CSV output\n",
    "    print(\"Generating predictions and saving to CSV...\")\n",
    "    predict_and_generate_csv(classifier_model, test_features, image_names, output_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7427d92f-dd30-43fd-bed2-9754f54c2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import InceptionResNetV2, InceptionV3\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = (256, 256)  # Reduced input size for models\n",
    "BATCH_SIZE = 16  # Reduced batch size\n",
    "EPOCHS = 15\n",
    "N_MODELS = 2  # Number of models per architecture\n",
    "\n",
    "# Load Data\n",
    "def load_data(csv_path, img_folder):\n",
    "    logging.info(\"Loading data from CSV and image folder...\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        img_path = os.path.join(img_folder, row['id_code'] + '.png')\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMG_SIZE)\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        images.append(img_array)\n",
    "        labels.append(row['diagnosis'])\n",
    "    \n",
    "    logging.info(f\"Loaded {len(images)} images and their labels.\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load Test Data\n",
    "def load_test_data(csv_path, img_folder):\n",
    "    logging.info(\"Loading test data from CSV and image folder...\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    images = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        img_path = os.path.join(img_folder, row['id_code'] + '.png')\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMG_SIZE)\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        images.append(img_array)\n",
    "\n",
    "    logging.info(f\"Loaded {len(images)} test images.\")\n",
    "    return np.array(images)\n",
    "\n",
    "# Data Augmentation\n",
    "def create_data_generator():\n",
    "    logging.info(\"Creating data generator with augmentations...\")\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    return datagen\n",
    "\n",
    "# Build Model\n",
    "def build_model(base_model):\n",
    "    logging.info(\"Building model...\")\n",
    "    model = Model(inputs=base_model.input, outputs=Dense(5, activation='softmax')(GlobalAveragePooling2D()(base_model.output)))\n",
    "    return model\n",
    "\n",
    "# Generalized Mean Pooling\n",
    "class GeM(tf.keras.layers.Layer):\n",
    "    def __init__(self, p=3, epsilon=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = tf.Variable(initial_value=p, trainable=False)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.reduce_mean(tf.maximum(x, self.epsilon) ** self.p, axis=(1, 2)) ** (1.0 / self.p)\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, X_train, y_train, X_val, y_val):\n",
    "    logging.info(\"Compiling model...\")\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "    logging.info(\"Starting model training...\")\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                        batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[es], verbose=1)\n",
    "    \n",
    "    logging.info(\"Training completed.\")\n",
    "    return model\n",
    "\n",
    "# Main Program\n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"Program started.\")\n",
    "\n",
    "    # Load Data\n",
    "    train_csv_path = '/kaggle/input/aptos2019-blindness-detection/train.csv'\n",
    "    train_images_folder = '/kaggle/input/aptos2019-blindness-detection/train_images'\n",
    "    \n",
    "    X, y = load_data(train_csv_path, train_images_folder)\n",
    "    X = X / 255.0  # Normalize images\n",
    "\n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Create data generator\n",
    "    datagen = create_data_generator()\n",
    "\n",
    "    # Model Definitions\n",
    "    models = []\n",
    "    for i in range(N_MODELS):\n",
    "        logging.info(f\"Loading model {i + 1}: Inception ResNet V2 and Inception V3...\")\n",
    "        base_model1 = InceptionResNetV2(weights='/kaggle/input/inception-resnet/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "        base_model2 = InceptionV3(weights='/kaggle/input/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "        \n",
    "        base_model1.layers[-1].trainable = False  # Freeze layers\n",
    "        base_model2.layers[-1].trainable = False\n",
    "        \n",
    "        model1 = build_model(base_model1)\n",
    "        model2 = build_model(base_model2)\n",
    "        models.append(model1)\n",
    "        models.append(model2)\n",
    "\n",
    "    # Train Models\n",
    "    for i, model in enumerate(models):\n",
    "        logging.info(f\"Training model {i + 1}...\")\n",
    "        train_model(model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "    # Ensemble Predictions\n",
    "    predictions = []\n",
    "    logging.info(\"Making predictions on validation set...\")\n",
    "    for model in models:\n",
    "        preds = model.predict(X_val)\n",
    "        predictions.append(preds)\n",
    "\n",
    "    # Average Predictions\n",
    "    avg_preds = np.mean(predictions, axis=0)\n",
    "    final_preds = np.argmax(avg_preds, axis=1)\n",
    "\n",
    "    # Calculate Kappa Score\n",
    "    kappa = cohen_kappa_score(y_val, final_preds)\n",
    "    logging.info(f'Validation Quadratic Weighted Kappa: {kappa:.4f}')\n",
    "\n",
    "    # Load Test Data\n",
    "    test_csv_path = '/kaggle/input/aptos2019-blindness-detection/test.csv'\n",
    "    test_images_folder = '/kaggle/input/aptos2019-blindness-detection/test_images'\n",
    "    \n",
    "    X_test = load_test_data(test_csv_path, test_images_folder)\n",
    "    X_test = X_test / 255.0  # Normalize test images\n",
    "\n",
    "    # Make Predictions on Test Data\n",
    "    test_predictions = []\n",
    "    logging.info(\"Making predictions on test data...\")\n",
    "    for model in models:\n",
    "        preds = model.predict(X_test)\n",
    "        test_predictions.append(preds)\n",
    "\n",
    "    # Average Test Predictions\n",
    "    avg_test_preds = np.mean(test_predictions, axis=0)\n",
    "    final_test_preds = np.argmax(avg_test_preds, axis=1)\n",
    "\n",
    "    # Create Submission DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        'id_code': pd.read_csv(test_csv_path)['id_code'],\n",
    "        'diagnosis': final_test_preds\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    submission_df.to_csv('submission.csv', index=False)\n",
    "    logging.info(\"Submission CSV file has been created and saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
